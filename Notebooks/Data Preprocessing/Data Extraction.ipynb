{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Extraction",
      "provenance": [],
      "collapsed_sections": [
        "jDq4cA0Tu37B",
        "g3a0CzCQrvRc"
      ],
      "authorship_tag": "ABX9TyMlVel0UpE3jRUXdQu2ecLm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FaridSharaf/30-Days-of-Code/blob/master/Notebooks/Data%20Preprocessing/Data%20Extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "U4fTGOhsQ98F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQkOCehjQ2Gs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cb_columns = ['Organization Name','Organization Name URL','Number of Contacts','Company Type',\n",
        "              'Operating Status','Last Funding Type','Industries','Description',\n",
        "              'Total Funding Amount','Total Funding Amount Currency','Total Funding Amount Currency (in USD)',\n",
        "              'Founded Date','Founded Date Precision','LinkedIn','Last Funding Date','Founders','Number of Founders',\n",
        "              'Headquarters Location', 'Headquarters Regions', 'Diversity Spotlight (US Only)', 'Estimated Revenue Range',\n",
        "              'Exit Date','Exit Date Precision','Closed Date','Closed Date Precision','Website',\n",
        "              'Twitter','Facebook','Contact Email','Number of Articles','Hub Tags','Full Description',\n",
        "              'Phone Number','Investment Stage','Number of Investments','Number of Lead Investments','Number of Exits',\n",
        "              'Number of Exits (IPO)','Number of Diversity Investments','Number of Portfolio Organizations','Accelerator Program Type',\n",
        "              'Accelerator Application Deadline','Accelerator Duration (in weeks)','Investor Type','Industry Groups','Number of Employees',\n",
        "              'Funding Status','Number of Funding Rounds','Last Funding Amount','Last Funding Amount Currency',\n",
        "              'Last Funding Amount Currency (in USD)','Last Equity Funding Amount','Last Equity Funding Amount Currency','Last Equity Funding Amount Currency (in USD)',\n",
        "              'Last Equity Funding Type','Total Equity Funding Amount','Total Equity Funding Amount Currency','Total Equity Funding Amount Currency (in USD)',\n",
        "              'Number of Investors','Number of Lead Investors','Top 5 Investors','Number of Acquisitions','Acquisition Status','Acquisition Terms',\n",
        "              'Acquisition Type','Price','Price Currency','Price Currency (in USD)','Announced Date',\n",
        "              'Announced Date Precision','Acquired by','Acquired by URL','Transaction Name','Transaction Name URL',\n",
        "              'Last Leadership Hiring Date','Last Layoff Mention Date','CB Rank (Organization)','CB Rank (Company)','SEMrush - Monthly Visits',\n",
        "              'SEMrush - Average Visits (6 months)','SEMrush - Monthly Visits Growth','SEMrush - Visit Duration','SEMrush - Visit Duration Growth',\n",
        "              'SEMrush - Page Views / Visit','SEMrush - Page Views / Visit Growth','SEMrush - Bounce Rate','SEMrush - Bounce Rate Growth',\n",
        "              'SEMrush - Global Traffic Rank','SEMrush - Monthly Rank Change (#)','SEMrush - Monthly Rank Growth','BuiltWith - Active Tech Count','Apptopia - Number of Apps',\n",
        "              'Apptopia - Downloads Last 30 Days','G2 Stack - Total Products Active','IPqwery - Patents Granted','IPqwery - Trademarks Registered',\n",
        "              'IPqwery - Most Popular Patent Class','IPqwery - Most Popular Trademark Class','Aberdeen - IT Spend','Aberdeen - IT Spend Currency','Aberdeen - IT Spend Currency (in USD)',\n",
        "              'Actively Hiring', 'founded_year', 'Founders_ID', 'founders_id_list', 'crunchbase_scraping_status', 'linkedin_scraping_status']\n",
        "\n",
        "linkedin_columns = ['total_management_exp', 'total_entrepreneurial_epx', \n",
        "                    'total_technical_exp', 'total_consulting_exp',\n",
        "                    'total_investment_banking_exp', 'sum_Bachelor_degree', \n",
        "                    'sum_master_degree', 'sum_MBA_degree', 'sum_PhD_degree',\n",
        "                    'avg_top_university', 'avg_technical_education', 'avg_management_education']\n",
        "\n",
        "trend_index_columns = ['keywords', 'Industry trend', 'Product trend']\n",
        "\n",
        "twitter_columns = [\"tweets_count\", \"avg_replies\", \"avg_retweets\", \"avg_likes\",  \"avg_lengths\", \n",
        "                   \"num_negative_tweets\", \"avg_negative_emotions\", \"num_positive_tweets\", \n",
        "                   \"avg_positive_emotions\", \"total_num_retweets_by_venture\", \"langs\"]"
      ],
      "metadata": {
        "id": "7PJHbbfp2NiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/startups_data.csv')"
      ],
      "metadata": {
        "id": "2MW837l4RFng"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Founders_ID'].fillna('nan', inplace = True)"
      ],
      "metadata": {
        "id": "z2WFEHDq-0yd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Operating Status'].value_counts()"
      ],
      "metadata": {
        "id": "Xtx2fwsyRsGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split founders string to a  list of founders"
      ],
      "metadata": {
        "id": "JJi_LCnjmTmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(founders):\n",
        "    flat_founders = []\n",
        "    for founder in founders:\n",
        "        if isinstance(founder, list):\n",
        "            flat_founders.extend(flatten(founder))\n",
        "        else:\n",
        "            flat_founders.append(founder)\n",
        "    return flat_founders"
      ],
      "metadata": {
        "id": "93hZ3I7qELpU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_founders(founders):\n",
        "    founders_list = []\n",
        "    if ',' in founders:\n",
        "        founders_list.append(founders.replace(\" \", \"\").split(','))\n",
        "        founders_list = flatten(founders_list)\n",
        "    else:\n",
        "        founders_list.append(founders)\n",
        "    return founders_list"
      ],
      "metadata": {
        "id": "lifucel1Ol3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['founders_id_list'] = df['Founders_ID'].apply(split_founders)\n",
        "df"
      ],
      "metadata": {
        "id": "ryUFCTRYmFlb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Check fully scraped companies "
      ],
      "metadata": {
        "id": "YCOK4XpOmPSK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "crunchbase_scraped_files_path = '/content/drive/MyDrive/1_Farid/1_startup_survivability/data/crunchbase/links'\n",
        "linkedin_scraped_files_path = '/content/drive/MyDrive/1_Farid/1_startup_survivability/data/Linkedin/linkedin_profiles'\n",
        "\n",
        "crunchbase_scraped_files = os.listdir('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/crunchbase/links')\n",
        "linkedin_scraped_files = os.listdir('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/Linkedin/linkedin_profiles')"
      ],
      "metadata": {
        "id": "CTLeiylJl4cH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Fully Scraped Companies"
      ],
      "metadata": {
        "id": "Z4Vyu0n7m63H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mapping(users, files_list):\n",
        "    scraping_status = 'Failed'\n",
        "    n = len(users)\n",
        "    scraped_users = 0\n",
        "    for user in users:\n",
        "        if user + '.json' in files_list:\n",
        "            scraped_users = scraped_users + 1\n",
        "        else:\n",
        "            scraping_status = 'Failed'\n",
        "\n",
        "    if scraped_users == n:\n",
        "        scraping_status = 'Done'\n",
        "    return scraping_status"
      ],
      "metadata": {
        "id": "DfRDZbjNl4XF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['crunchbase_scraping_status'] = df.apply(lambda x: mapping(x['founders_id_list'], crunchbase_scraped_files), axis = 1)\n",
        "# df.head(3)"
      ],
      "metadata": {
        "id": "CozfOJxUl4Ur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['linkedin_scraping_status'] = df.apply(lambda x: mapping(x['founders_id_list'], linkedin_scraped_files), axis = 1)\n",
        "# df.head(3)"
      ],
      "metadata": {
        "id": "5PVlDrr_l4SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['linkedin_scraping_status'].value_counts()"
      ],
      "metadata": {
        "id": "vp17Uus-l4Po"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['crunchbase_scraping_status'].value_counts()"
      ],
      "metadata": {
        "id": "GCA9YYbKeGhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linkedin_scraped_df = df[df['linkedin_scraping_status'] == 'Done'].copy()"
      ],
      "metadata": {
        "id": "cKv2PELABRrr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "crunchbase_scraped_df = df[df['crunchbase_scraping_status'] == 'Done'].copy()"
      ],
      "metadata": {
        "id": "p2-PuhIke024"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(df[df['crunchbase_scraping_status'] == 'Failed']['founders_id_list']))"
      ],
      "metadata": {
        "id": "Toi2cdx-nTZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract Non-scraped Crunchbase Users"
      ],
      "metadata": {
        "id": "jDq4cA0Tu37B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "non_scraped_crunchbase_users = df[df['crunchbase_scraping_status'] == 'Failed']['founders_id_list']\n",
        "non_scraped_crunchbase_users[:10]"
      ],
      "metadata": {
        "id": "sdcJ-OeMnTUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten(founders):\n",
        "    all_founders = []\n",
        "    flat_founders = []\n",
        "    for founder in founders:\n",
        "        if ',' in founder:\n",
        "            all_founders.append(founder.replace(\" \", '').split(','))\n",
        "        else:\n",
        "            all_founders.append(founder)\n",
        "\n",
        "    for founder in all_founders:\n",
        "        if isinstance(founder, list):\n",
        "            flat_founders.extend(flatten(founder))\n",
        "        else:\n",
        "            flat_founders.append(founder)\n",
        "    return flat_founders"
      ],
      "metadata": {
        "id": "wrew4FuNnTR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_scraped_crunchbase_users = flatten(non_scraped_crunchbase_users)\n",
        "non_scraped_crunchbase_users[:10]"
      ],
      "metadata": {
        "id": "ElrjSUIyEMln"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(non_scraped_crunchbase_users)"
      ],
      "metadata": {
        "id": "nHu60GJ6nTPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "o4CQ9-gynTNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = np.array_split(non_scraped_crunchbase_users, 2)"
      ],
      "metadata": {
        "id": "z2w2TlGt2NM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(lst)"
      ],
      "metadata": {
        "id": "j7LCh5IJ4JhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i = 1\n",
        "for pic in lst:\n",
        "    with open(f'/content/drive/MyDrive/1_Farid/temp/cb_nonscraped/users_list{i}', 'wb') as output_file:\n",
        "        pickle.dump(pic, output_file)\n",
        "    i = i + 1"
      ],
      "metadata": {
        "id": "WkTx2tN42pJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# with open(f'/content/drive/MyDrive/1_Farid/temp/cb_nonscraped/users_list1', 'rb') as input_file:\n",
        "#         lsls = pickle.load(input_file)"
      ],
      "metadata": {
        "id": "jvN0UScT2qJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# lsls[:10]"
      ],
      "metadata": {
        "id": "mrV5Lwo24esP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Merge Data"
      ],
      "metadata": {
        "id": "g3a0CzCQrvRc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_cols = cb_columns + trend_index_columns + twitter_columns + linkedin_columns"
      ],
      "metadata": {
        "id": "aOAzJ6sdrywz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/raw_startups.csv')\n",
        "# raw_df = df.copy()"
      ],
      "metadata": {
        "id": "V2MCu01iryuD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linkedin_df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/linkedin_data.csv', usecols = ['Organization Name URL'] + linkedin_columns)"
      ],
      "metadata": {
        "id": "Hj-wshdbryq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trend_df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/trend_index_data.csv', usecols = ['Organization Name URL'] + trend_index_columns)"
      ],
      "metadata": {
        "id": "DqJPM20Uryny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitter_df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/twitter_data.csv', usecols = ['Organization Name URL'] + twitter_columns)"
      ],
      "metadata": {
        "id": "tAwCeE6rrykr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups = pd.merge(raw_df, trend_df, on = 'Organization Name URL', how= 'left')"
      ],
      "metadata": {
        "id": "WM-RRVjarygv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups = pd.merge(startups, twitter_df, on = 'Organization Name URL', how= 'left')"
      ],
      "metadata": {
        "id": "V7MlKDQPrydj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups = pd.merge(startups, linkedin_df, on = 'Organization Name URL', how= 'left')"
      ],
      "metadata": {
        "id": "jVqJfzmqug4O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups.to_csv('/content/', index =False, columns = all_cols)"
      ],
      "metadata": {
        "id": "Rzcyjp8juqNd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vbd5wxiSdvOO"
      },
      "source": [
        "# Fix Companies Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgQE-omzdvOP"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('../../Data/startups_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4FXBNB2PdvOQ"
      },
      "outputs": [],
      "source": [
        "fixed_companies = pd.read_csv('/content/drive/MyDrive/1_Farid/temp/companies/labeled_companies - original_open.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXYOm70JdvOQ"
      },
      "outputs": [],
      "source": [
        "fixed_companies['SocialMedia Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fixed_companies.loc[(~pd.isna(fixed_companies['SocialMedia Status'])) & (fixed_companies['SocialMedia Status'] != \"Active\") & (fixed_companies['SocialMedia Status'] != \"Closed\")]"
      ],
      "metadata": {
        "id": "1Ja_JwXSJOBI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Rzopl6sdvOR"
      },
      "outputs": [],
      "source": [
        "open_fixed_companies = fixed_companies[fixed_companies['SocialMedia Status'] == 'Active']['Organization Name URL'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1rETTBm7dvOR"
      },
      "outputs": [],
      "source": [
        "closed_fixed_companies = fixed_companies[fixed_companies['SocialMedia Status'] == 'Closed']['Organization Name URL'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ye1G23Q3dvOS"
      },
      "outputs": [],
      "source": [
        "# df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_l1SKCDLdvOS"
      },
      "outputs": [],
      "source": [
        "def modify_companies(row, lis):\n",
        "    if row['Organization Name URL'] in lis:\n",
        "        row['Operating Status'] = \"Closed\"\n",
        "    return row"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Clc6kecxdvOS"
      },
      "outputs": [],
      "source": [
        "df = df.apply(lambda x: modify_companies(x, closed_fixed_companies), axis = 1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xa6GcZxUdvOT"
      },
      "outputs": [],
      "source": [
        "df['Operating Status'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1Y0rOVLdvOU"
      },
      "outputs": [],
      "source": [
        "linkedin_df = df[df['linkedin_scraping_status'] == \"Failed\"].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TzQNGXizdvOU"
      },
      "outputs": [],
      "source": [
        "closed_list = linkedin_df[linkedin_df['Operating Status'] == 'Closed']['Founders_ID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j10KWKkVdvOU"
      },
      "outputs": [],
      "source": [
        "linkedin_df['founders_id_list'] = linkedin_df['Founders_ID'].apply(split_founders)\n",
        "linkedin_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C__6PsscdvOV"
      },
      "outputs": [],
      "source": [
        "len(closed_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4T0csPOdvOV"
      },
      "outputs": [],
      "source": [
        "closed_list = flatten(closed_list)\n",
        "len(closed_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qOqqNd2idvOV"
      },
      "outputs": [],
      "source": [
        "closed_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxoRuomJdvOV"
      },
      "outputs": [],
      "source": [
        "    with open(f'../lost_linkedin', 'wb') as output_file:\n",
        "        pickle.dump(closed_list, output_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KA6vGb7dvOV"
      },
      "outputs": [],
      "source": [
        "df.to_csv('../../startups_data.csv', index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJf48zgEdvOW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Acquired Companies"
      ],
      "metadata": {
        "id": "7mqWDm_T6_mg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_acquired_companies(row):\n",
        "    if (row['Operating Status'] == \"Closed\") and (row['Acquisition Status'] == \"Was Acquired\"):\n",
        "        row['Operating Status'] = \"Active\"\n",
        "    return row"
      ],
      "metadata": {
        "id": "atEMPsxC7GeA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.apply(modify_acquired_companies, axis = 1).copy()"
      ],
      "metadata": {
        "id": "iMKbThDNAlqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Operating Status'].value_counts()"
      ],
      "metadata": {
        "id": "7-m6_FbhSvp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/startups_data.csv', index = False)"
      ],
      "metadata": {
        "id": "2x9LJkYNS4P9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sample Extraction"
      ],
      "metadata": {
        "id": "Jlf44HpmzbRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/startups_data.csv')"
      ],
      "metadata": {
        "id": "AhljZ5lYHbx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Operating Status'].value_counts()"
      ],
      "metadata": {
        "id": "IYJwLo5dHuGp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "closed_companies = df[df['Operating Status'] == \"Closed\"].copy()"
      ],
      "metadata": {
        "id": "5B8faMz5zcAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "open_companies = df.loc[(df['Operating Status'] == 'Active') & (df['linkedin_scraping_status'] == 'Done')].sample(2000)"
      ],
      "metadata": {
        "id": "a8_hKYSDzvIy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups_sample = pd.concat([open_companies, closed_companies], ignore_index = True, sort = False)"
      ],
      "metadata": {
        "id": "YCgy2LorzbgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "startups_sample.to_csv('/content/drive/MyDrive/1_Farid/1_startup_survivability/data/startups/startups_sample.csv', index = False)"
      ],
      "metadata": {
        "id": "KHvj41XBCtAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_8m1rg6AIWKy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}